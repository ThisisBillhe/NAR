# Neighboring Autoregressive Modeling for Efficient Visual Generation


<div align="center">

[![arXiv](https://img.shields.io/badge/arXiv%20paper-2406.06525-b31b1b.svg)](https://arxiv.org/abs/2406.06525)&nbsp;
[![project page](https://img.shields.io/badge/Project_page-More_visualizations-green)](https://peizesun.github.io/llamagen/)&nbsp;

</div>


<p align="center">
<img src="assets/teaser.jpg" width=95%>
<p>

## Demo Video

<p align="center">
<video width="95%" controls>
  <source src="assets/demo_video.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
</p>

## ðŸ”¥ Update
- [2025.03.14] C2i, t2i, c2v training and sampling code are released !

## ðŸŒ¿ Introduction
We introduce NAR, a new "next-neighbor prediction" paradigm for efficient and high-quality visual generation. NAR achieves state-of-the-art generation quality and efficiency trade-off for both image and video generation tasks. All the training codes, data and models are open-sourced.

All pretrained models can be downloaded from [HuggingFace](https://huggingface.co/collections/chenfeng1271/nar-67d13fa93fe913b2e187ee1f).

## BibTeX
```bibtex
@article{sun2024autoregressive,
  title={Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation},
  author={Sun, Peize and Jiang, Yi and Chen, Shoufa and Zhang, Shilong and Peng, Bingyue and Luo, Ping and Yuan, Zehuan},
  journal={arXiv preprint arXiv:2406.06525},
  year={2024}
}
```